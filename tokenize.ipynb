{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc \n",
    "#from spacy.tokenizer import Tokenizer\n",
    "#from spacy.lang.en import English\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyl\\anaconda3\\lib\\site-packages\\fastbook\\__init__.py:18: UserWarning: Missing `graphviz` - please run `conda install fastbook`\n",
      "  except ModuleNotFoundError: warn(\"Missing `graphviz` - please run `conda install fastbook`\")\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#!pip install -Uqq fastbook\n",
    "#hide\n",
    "from fastbook import *\n",
    "from IPython.display import display,HTML\n",
    "from fastai.text.all import *\n",
    "from fastai.text.all import Tokenizer as Tokenize\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 150\n",
    "df = pd.read_csv(\"cleand_tweet.csv\")\n",
    "\n",
    "# df.tweet = df.tweet.str.split(pat=': ').str[-1]\n",
    "# df.tweet.to_csv(\"df_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19500"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['tweet'].str.contains('http')].reset_index()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    \" fuck no that bitch dont even suck dick \" &#128514;&#128514;&#128514; the Kermit videos bout to fuck IG up\n",
       "23                                                                 \" her pussy lips like Heaven doors \" &#128524;\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][22:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How u gone bring ur side bitch to a game where DorothyYou know Ya gf friDorothyends at ?! DorothyDorothy\" I SWEAR!!!!!'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.tweet[51]\n",
    "rnd_name = str(names.get_first_name())\n",
    "matched = re.sub('@.+?(\\b|\\s|$)', rnd_name+str(' '), test)\n",
    "matched\n",
    "test_2 = 'How u gone bring ur side bitch to a game where &#128553;You know Ya gf fri&#128553;ends at ?! &#128553;&#128553;\" I SWEAR!!!!!'\n",
    "matched_2 = re.sub('&#.+?;', rnd_name+str(''), test_2)\n",
    "matched_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-180-480d5481ee68>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'][i]  = re.sub('@.+?(\\b|\\s|$)', rnd_name+str(' '), df['tweet'][i])\n",
      "<ipython-input-180-480d5481ee68>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'][i]  = re.sub('&.+?;', '', df['tweet'][i])\n"
     ]
    }
   ],
   "source": [
    "import names\n",
    "\n",
    "for i in range(len(df['tweet'])):\n",
    "    rnd_name = str(names.get_first_name())\n",
    "    df['tweet'][i]  = re.sub('@.+?(\\b|\\s|$)', rnd_name+str(' '), df['tweet'][i])\n",
    "    df['tweet'][i]  = re.sub('&.+?;', '', df['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleand_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer()\n",
    "tkn = Tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alma she look like a tranny\n",
      "(#8) ['xxbos','xxmaj','alma','she','look','like','a','tranny']\n"
     ]
    }
   ],
   "source": [
    "print(df.tweet[2])\n",
    "print(coll_repr(tkn(df.tweet[2]), 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#18) ['xxbos','boy','dats','cold','…','tyga','dwn','bad','for','cuffin','dat','hoe','in','the','1st','place','!','!']\n"
     ]
    }
   ],
   "source": [
    "toks200 = df.tweet[:200].map(tkn)\n",
    "print(coll_repr(toks200[0], 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#200) [\\'xxunk\\',\\'xxpad\\',\\'xxbos\\',\\'xxeos\\',\\'xxfld\\',\\'xxrep\\',\\'xxwrep\\',\\'xxup\\',\\'xxmaj\\',\\'\"\\',\\'i\\',\\'bitch\\',\\'.\\',\\'a\\',\\'you\\',\\'the\\',\\'that\\',\\'to\\',\\'!\\',\"n\\'t\",\\'bitches\\',\\'hoes\\',\\'do\\',\\'my\\',\\'like\\',\\'me\\',\\',\\',\\'pussy\\',\\'be\\',\\'for\\',\\'?\\',\\'on\\',\\'up\\',\\'is\\',\\'in\\',\\'and\\',\\'it\\',\\'with\\',\\'get\\',\\'these\\',\\'if\\',\\'…\\',\"\\'m\",\\'of\\',\\'shit\\',\\'..\\',\\'nt\\',\\'all\\',\\'fuck\\',\\'but\\'...]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "coll_repr(num.vocab,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums200 = toks200.map(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 57]), torch.Size([64, 57]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = first(dl)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxunk xxunk xxunk … xxunk xxunk bad for xxunk xxunk hoe in the xxunk xxunk ! ! xxbos xxmaj'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking\n",
    "' '.join(num.vocab[o] for o in x[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyl\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dls = TextDataLoaders.from_df(df, text_col='tweet', is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learn = language_model_learner(\n",
    "    dls, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Ti'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.876323</td>\n",
       "      <td>4.533437</td>\n",
       "      <td>0.224273</td>\n",
       "      <td>93.077942</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('10epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = torch.load('models/finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.350114</td>\n",
       "      <td>4.937599</td>\n",
       "      <td>0.209527</td>\n",
       "      <td>139.435028</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.819173</td>\n",
       "      <td>4.497620</td>\n",
       "      <td>0.236074</td>\n",
       "      <td>89.803108</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.448807</td>\n",
       "      <td>4.331578</td>\n",
       "      <td>0.257218</td>\n",
       "      <td>76.064201</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.159441</td>\n",
       "      <td>4.299310</td>\n",
       "      <td>0.261147</td>\n",
       "      <td>73.648941</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.830266</td>\n",
       "      <td>4.357162</td>\n",
       "      <td>0.257637</td>\n",
       "      <td>78.035355</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.500044</td>\n",
       "      <td>4.462615</td>\n",
       "      <td>0.253428</td>\n",
       "      <td>86.714012</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.131141</td>\n",
       "      <td>4.609733</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>100.457336</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.820148</td>\n",
       "      <td>4.754954</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>116.158295</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.587677</td>\n",
       "      <td>4.842947</td>\n",
       "      <td>0.244403</td>\n",
       "      <td>126.842667</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.463525</td>\n",
       "      <td>4.874281</td>\n",
       "      <td>0.243503</td>\n",
       "      <td>130.880066</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEXT = \"My friend Truman\"\n",
    "N_WORDS = 50\n",
    "N_SENTENCES = 2\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
    "         for _ in range(N_SENTENCES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted sentence: My friend Truman\n",
      "\n",
      "Generated sentences...\n",
      "My friend Xxunk got all the bitches On some real shit , i think i been in a fucking crib .. June Calm down you little Asian bitch … . When people say \" god only listen \" against the word hoe , they argue\n",
      "My friend Xxunk is a fucking bitch . Who 's your mom ? Why is Washington Redskins no pride ? Fuck . Mom ! ! Steve why ? Fuck u stupid hoe I 'm fuckin up and not everyone bout Lmfa\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputted sentence: \"+TEXT)\n",
    "print(\"\\nGenerated sentences...\")\n",
    "print(\"\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
