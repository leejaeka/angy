{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc \n",
    "#from spacy.tokenizer import Tokenizer\n",
    "#from spacy.lang.en import English\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.1.5 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.1.5 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "distributed 2021.5.0 requires dask==2021.05.0, but you have dask 2021.4.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "#hide\n",
    "from fastbook import *\n",
    "from IPython.display import display,HTML\n",
    "from fastai.text.all import *\n",
    "from fastai.text.all import Tokenizer as Tokenize\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 150\n",
    "df = pd.read_csv(\"df_tweet.csv\")\n",
    "\n",
    "# df.tweet = df.tweet.str.split(pat=': ').str[-1]\n",
    "# df.tweet.to_csv(\"df_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19500"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['tweet'].str.contains('http')].reset_index()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22    \" fuck no that bitch dont even suck dick \" &#128514;&#128514;&#128514; the Kermit videos bout to fuck IG up\n",
       "23                                                                 \" her pussy lips like Heaven doors \" &#128524;\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][22:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How u gone bring ur side bitch to a game where DorothyYou know Ya gf friDorothyends at ?! DorothyDorothy\" I SWEAR!!!!!'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.tweet[51]\n",
    "rnd_name = str(names.get_first_name())\n",
    "matched = re.sub('@.+?(\\b|\\s|$)', rnd_name+str(' '), test)\n",
    "matched\n",
    "test_2 = 'How u gone bring ur side bitch to a game where &#128553;You know Ya gf fri&#128553;ends at ?! &#128553;&#128553;\" I SWEAR!!!!!'\n",
    "matched_2 = re.sub('&#.+?;', rnd_name+str(''), test_2)\n",
    "matched_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-180-480d5481ee68>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'][i]  = re.sub('@.+?(\\b|\\s|$)', rnd_name+str(' '), df['tweet'][i])\n",
      "<ipython-input-180-480d5481ee68>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'][i]  = re.sub('&.+?;', '', df['tweet'][i])\n"
     ]
    }
   ],
   "source": [
    "import names\n",
    "\n",
    "for i in range(len(df['tweet'])):\n",
    "    rnd_name = str(names.get_first_name())\n",
    "    df['tweet'][i]  = re.sub('@.+?(\\b|\\s|$)', rnd_name+str(' '), df['tweet'][i])\n",
    "    df['tweet'][i]  = re.sub('&.+?;', '', df['tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleand_tweet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordTokenizer()\n",
    "tkn = Tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alma she look like a tranny\n",
      "(#8) ['xxbos','xxmaj','alma','she','look','like','a','tranny']\n"
     ]
    }
   ],
   "source": [
    "print(df.tweet[2])\n",
    "print(coll_repr(tkn(df.tweet[2]), 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#18) ['xxbos','boy','dats','cold','…','tyga','dwn','bad','for','cuffin','dat','hoe','in','the','1st','place','!','!']\n"
     ]
    }
   ],
   "source": [
    "toks200 = df.tweet[:200].map(tkn)\n",
    "print(coll_repr(toks200[0], 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(#200) [\\'xxunk\\',\\'xxpad\\',\\'xxbos\\',\\'xxeos\\',\\'xxfld\\',\\'xxrep\\',\\'xxwrep\\',\\'xxup\\',\\'xxmaj\\',\\'\"\\',\\'i\\',\\'bitch\\',\\'.\\',\\'a\\',\\'you\\',\\'the\\',\\'that\\',\\'to\\',\\'!\\',\"n\\'t\",\\'bitches\\',\\'hoes\\',\\'do\\',\\'my\\',\\'like\\',\\'me\\',\\',\\',\\'pussy\\',\\'be\\',\\'for\\',\\'?\\',\\'on\\',\\'up\\',\\'is\\',\\'in\\',\\'and\\',\\'it\\',\\'with\\',\\'get\\',\\'these\\',\\'if\\',\\'…\\',\"\\'m\",\\'of\\',\\'shit\\',\\'..\\',\\'nt\\',\\'all\\',\\'fuck\\',\\'but\\'...]'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = Numericalize()\n",
    "num.setup(toks200)\n",
    "coll_repr(num.vocab,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums200 = toks200.map(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(nums200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 57]), torch.Size([64, 57]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = first(dl)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxunk xxunk xxunk … xxunk xxunk bad for xxunk xxunk hoe in the xxunk xxunk ! ! xxbos xxmaj'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking\n",
    "' '.join(num.vocab[o] for o in x[0][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyl\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "dls = TextDataLoaders.from_df(df, text_col='tweet', is_lm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learn = language_model_learner(\n",
    "    dls, AWD_LSTM, drop_mult=0.3, \n",
    "    metrics=[accuracy, Perplexity()]).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060 Ti'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.876323</td>\n",
       "      <td>4.533437</td>\n",
       "      <td>0.224273</td>\n",
       "      <td>93.077942</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('10epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('10epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.341064</td>\n",
       "      <td>4.406570</td>\n",
       "      <td>0.242332</td>\n",
       "      <td>81.987801</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.234272</td>\n",
       "      <td>4.334343</td>\n",
       "      <td>0.242510</td>\n",
       "      <td>76.274826</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.051903</td>\n",
       "      <td>4.294801</td>\n",
       "      <td>0.258337</td>\n",
       "      <td>73.317604</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.775156</td>\n",
       "      <td>4.349750</td>\n",
       "      <td>0.257440</td>\n",
       "      <td>77.459099</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.435732</td>\n",
       "      <td>4.463824</td>\n",
       "      <td>0.252952</td>\n",
       "      <td>86.818855</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.083234</td>\n",
       "      <td>4.642047</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>103.756561</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.712221</td>\n",
       "      <td>4.816313</td>\n",
       "      <td>0.240571</td>\n",
       "      <td>123.508904</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.401290</td>\n",
       "      <td>4.968582</td>\n",
       "      <td>0.237575</td>\n",
       "      <td>143.822754</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.204347</td>\n",
       "      <td>5.044863</td>\n",
       "      <td>0.236154</td>\n",
       "      <td>155.223068</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.076193</td>\n",
       "      <td>5.075380</td>\n",
       "      <td>0.236039</td>\n",
       "      <td>160.032974</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEXT = \"My friend Dudu\"\n",
    "N_WORDS = 50\n",
    "N_SENTENCES = 2\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
    "         for _ in range(N_SENTENCES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted sentence: My friend Dudu\n",
      "\n",
      "Generated sentences...\n",
      "My friend Xxunk is a bitch If Nick Cannon was nt supposed to get his ass beat in this fight he 's a lil bitch Eric Yankee games are so funny . Any bitch who did it in baseball is the ultimate bitch .\n",
      "My friend Xxunk said \" i wanna suck your dick when i take it from the bitches \" … I m a act like a bitch My dad just told his dad to leave them crib bitches saying \" i 'm a cold ass bitch \" I 'm\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputted sentence: \"+TEXT)\n",
    "print(\"\\nGenerated sentences...\")\n",
    "print(\"\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
